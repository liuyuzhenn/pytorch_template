# see: https://pytorch.org/docs/stable/optim.html
name: "Adam" # necessary
lr: 0.01
betas: [0.9, 0.999]
weight_decay: 0.0
lr_scheduler:
  name: "ExponentialLR"
  gamma: 0.999
# lr_scheduler:
#   name: "LambdaLR"
#   lr_lambda: "lambda p: 0.99**p"
